{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=[ 'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the vocabulary size\n",
    "voc_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sent)\n",
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 2, 8],\n",
       " [1, 4, 2, 9],\n",
       " [1, 10, 2, 11],\n",
       " [5, 6, 7, 3, 12],\n",
       " [5, 6, 7, 3, 13],\n",
       " [14, 1, 15, 2, 16],\n",
       " [17, 18, 19, 3]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### One Hot Representation\n",
    "one_hot_repr = [tokenizer.texts_to_sequences([sentence])[0] for sentence in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word embedding \n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of words in a sentence: 5\n",
      "Sentence(s) with the maximum number of words: ['I am a good boy', 'I am a good developer', 'understand the meaning of words']\n",
      "Minimum number of words in a sentence: 4\n",
      "Sentence(s) with the minimum number of words: ['the glass of milk', 'the glass of juice', 'the cup of tea', 'your videos are good']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calculate the number of words in each sentence\n",
    "word_counts = [len(sentence.split()) for sentence in sent]\n",
    "\n",
    "# Step 2: Find the maximum and minimum number of words\n",
    "max_words = max(word_counts)\n",
    "min_words = min(word_counts)\n",
    "\n",
    "# Step 3: Find the sentence(s) with the maximum and minimum number of words\n",
    "max_sentences = [sentence for sentence in sent if len(sentence.split()) == max_words]\n",
    "min_sentences = [sentence for sentence in sent if len(sentence.split()) == min_words]\n",
    "\n",
    "# Output the results\n",
    "print(\"Maximum number of words in a sentence:\", max_words)\n",
    "print(\"Sentence(s) with the maximum number of words:\", max_sentences)\n",
    "print(\"Minimum number of words in a sentence:\", min_words)\n",
    "print(\"Sentence(s) with the minimum number of words:\", min_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  1,  4,  2,  8],\n",
       "       [ 0,  0,  0,  0,  1,  4,  2,  9],\n",
       "       [ 0,  0,  0,  0,  1, 10,  2, 11],\n",
       "       [ 0,  0,  0,  5,  6,  7,  3, 12],\n",
       "       [ 0,  0,  0,  5,  6,  7,  3, 13],\n",
       "       [ 0,  0,  0, 14,  1, 15,  2, 16],\n",
       "       [ 0,  0,  0,  0, 17, 18, 19,  3]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding is done to make the length of the sentences same \n",
    "sent_length=8\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)\n",
    "embedded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature representation\n",
    "# using low value as the data is very small higher value tends to overfit\n",
    "dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 8, 10)             100000    \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [-0.03771061,  0.04773815, -0.03868502, -0.03920982,\n",
       "         -0.00615809, -0.02046227, -0.04131862,  0.01830781,\n",
       "         -0.02059578,  0.0081237 ],\n",
       "        [ 0.01453868, -0.04350867,  0.01670432, -0.01295882,\n",
       "          0.03588894,  0.02593361,  0.03441106, -0.01329154,\n",
       "          0.04564977, -0.02829648],\n",
       "        [-0.00061341,  0.03806886, -0.0399695 , -0.01853248,\n",
       "          0.01240562, -0.03642797,  0.03703458,  0.0118134 ,\n",
       "         -0.00720908,  0.04298294],\n",
       "        [ 0.04781449, -0.01780355,  0.04883948, -0.03358974,\n",
       "         -0.03740492, -0.02277376, -0.017623  , -0.01776488,\n",
       "          0.02166455, -0.0043443 ]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [-0.03771061,  0.04773815, -0.03868502, -0.03920982,\n",
       "         -0.00615809, -0.02046227, -0.04131862,  0.01830781,\n",
       "         -0.02059578,  0.0081237 ],\n",
       "        [ 0.01453868, -0.04350867,  0.01670432, -0.01295882,\n",
       "          0.03588894,  0.02593361,  0.03441106, -0.01329154,\n",
       "          0.04564977, -0.02829648],\n",
       "        [-0.00061341,  0.03806886, -0.0399695 , -0.01853248,\n",
       "          0.01240562, -0.03642797,  0.03703458,  0.0118134 ,\n",
       "         -0.00720908,  0.04298294],\n",
       "        [ 0.04169886, -0.00769316, -0.02036433, -0.03184203,\n",
       "          0.02239553, -0.0458119 , -0.04767028,  0.03146762,\n",
       "         -0.00662407, -0.02400233]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [-0.03771061,  0.04773815, -0.03868502, -0.03920982,\n",
       "         -0.00615809, -0.02046227, -0.04131862,  0.01830781,\n",
       "         -0.02059578,  0.0081237 ],\n",
       "        [-0.00763199,  0.03202179, -0.00375711,  0.0307868 ,\n",
       "         -0.02486898, -0.03852242, -0.03418665, -0.00250424,\n",
       "          0.01243349, -0.00205775],\n",
       "        [-0.00061341,  0.03806886, -0.0399695 , -0.01853248,\n",
       "          0.01240562, -0.03642797,  0.03703458,  0.0118134 ,\n",
       "         -0.00720908,  0.04298294],\n",
       "        [-0.03901894,  0.01493422,  0.00916761,  0.04810754,\n",
       "          0.00318313,  0.02949771, -0.0081354 , -0.01017417,\n",
       "          0.01531371,  0.02829636]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [-0.01631095,  0.00834849,  0.0395666 , -0.04148003,\n",
       "          0.02217526, -0.01418989,  0.01914761,  0.04675803,\n",
       "          0.0016655 , -0.04673568],\n",
       "        [ 0.00125561, -0.04893959, -0.02557653, -0.00658454,\n",
       "          0.03583572,  0.02758885, -0.01046373,  0.00882322,\n",
       "          0.02410538, -0.04345446],\n",
       "        [ 0.04436262, -0.02795401,  0.01601564,  0.04500934,\n",
       "         -0.02873763, -0.03877057, -0.01149564, -0.04540519,\n",
       "          0.00720227, -0.04631367],\n",
       "        [-0.04847426,  0.02445385,  0.00553743,  0.03977612,\n",
       "         -0.00222714, -0.02559768, -0.0366714 , -0.02416618,\n",
       "          0.0387296 , -0.00882103],\n",
       "        [-0.00213983, -0.0447537 , -0.01328199,  0.02432011,\n",
       "          0.0429959 , -0.00575085,  0.02277258,  0.03591465,\n",
       "          0.03290716, -0.0458712 ]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [-0.01631095,  0.00834849,  0.0395666 , -0.04148003,\n",
       "          0.02217526, -0.01418989,  0.01914761,  0.04675803,\n",
       "          0.0016655 , -0.04673568],\n",
       "        [ 0.00125561, -0.04893959, -0.02557653, -0.00658454,\n",
       "          0.03583572,  0.02758885, -0.01046373,  0.00882322,\n",
       "          0.02410538, -0.04345446],\n",
       "        [ 0.04436262, -0.02795401,  0.01601564,  0.04500934,\n",
       "         -0.02873763, -0.03877057, -0.01149564, -0.04540519,\n",
       "          0.00720227, -0.04631367],\n",
       "        [-0.04847426,  0.02445385,  0.00553743,  0.03977612,\n",
       "         -0.00222714, -0.02559768, -0.0366714 , -0.02416618,\n",
       "          0.0387296 , -0.00882103],\n",
       "        [-0.0345147 ,  0.03241124, -0.02080212, -0.04357524,\n",
       "          0.03118506, -0.03243933,  0.04547491,  0.02378779,\n",
       "         -0.03536844,  0.00181881]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [-0.02700001, -0.03526986,  0.009681  , -0.03275812,\n",
       "          0.03301461,  0.00705754,  0.01769399, -0.01732622,\n",
       "         -0.03642925,  0.03242191],\n",
       "        [-0.03771061,  0.04773815, -0.03868502, -0.03920982,\n",
       "         -0.00615809, -0.02046227, -0.04131862,  0.01830781,\n",
       "         -0.02059578,  0.0081237 ],\n",
       "        [-0.03607272,  0.00315765, -0.00129894, -0.03085842,\n",
       "          0.0068035 , -0.03410963, -0.04111373, -0.04520759,\n",
       "         -0.04169995, -0.00889749],\n",
       "        [-0.00061341,  0.03806886, -0.0399695 , -0.01853248,\n",
       "          0.01240562, -0.03642797,  0.03703458,  0.0118134 ,\n",
       "         -0.00720908,  0.04298294],\n",
       "        [ 0.00778366, -0.01345805, -0.00826292,  0.03228387,\n",
       "         -0.00361706, -0.0074548 ,  0.02433789,  0.009453  ,\n",
       "         -0.02194451, -0.04692168]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582],\n",
       "        [ 0.02752301, -0.04993367,  0.0409825 , -0.02663823,\n",
       "         -0.03463265,  0.00411563, -0.00232513, -0.00781361,\n",
       "          0.01793203,  0.04041961],\n",
       "        [-0.02939688, -0.00714916, -0.02128567, -0.00436059,\n",
       "          0.02200894, -0.02877218, -0.04929803, -0.03829692,\n",
       "         -0.00143195,  0.04474915],\n",
       "        [-0.00480192, -0.03329978,  0.03412613, -0.02252059,\n",
       "         -0.02092621,  0.02270924, -0.00419546,  0.04145968,\n",
       "          0.02958527, -0.02158642],\n",
       "        [-0.04847426,  0.02445385,  0.00553743,  0.03977612,\n",
       "         -0.00222714, -0.02559768, -0.0366714 , -0.02416618,\n",
       "          0.0387296 , -0.00882103]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 4, 2, 8])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582]],\n",
       "\n",
       "       [[ 0.00240875, -0.04836702, -0.01521522, -0.02489507,\n",
       "          0.03593007,  0.04675932,  0.04894478,  0.02997616,\n",
       "          0.0292495 , -0.03552582]],\n",
       "\n",
       "       [[-0.03771061,  0.04773815, -0.03868502, -0.03920982,\n",
       "         -0.00615809, -0.02046227, -0.04131862,  0.01830781,\n",
       "         -0.02059578,  0.0081237 ]],\n",
       "\n",
       "       [[ 0.01453868, -0.04350867,  0.01670432, -0.01295882,\n",
       "          0.03588894,  0.02593361,  0.03441106, -0.01329154,\n",
       "          0.04564977, -0.02829648]],\n",
       "\n",
       "       [[-0.00061341,  0.03806886, -0.0399695 , -0.01853248,\n",
       "          0.01240562, -0.03642797,  0.03703458,  0.0118134 ,\n",
       "         -0.00720908,  0.04298294]],\n",
       "\n",
       "       [[ 0.04781449, -0.01780355,  0.04883948, -0.03358974,\n",
       "         -0.03740492, -0.02277376, -0.017623  , -0.01776488,\n",
       "          0.02166455, -0.0043443 ]]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Notes\n",
    "\n",
    "Input Shape:\n",
    "\n",
    "Your input to the model is embedded_docs[0], which has the shape (8,). This means it's a 1D array with 8 elements (each element is an integer representing a word index).\n",
    "\n",
    "Embedding Layer:\n",
    "\n",
    "The Embedding layer converts each word index into a dense vector of size dim=10.\n",
    "\n",
    "Since the input has 8 word indices, the output will have 8 vectors, each of size 10.\n",
    "\n",
    "Output Shape:\n",
    "\n",
    "The output shape is (8, 10), where:\n",
    "\n",
    "8 corresponds to the number of words in the input sequence.\n",
    "\n",
    "10 corresponds to the dimensionality of the word embeddings (dim=10).\n",
    "\n",
    "Batch Dimension:\n",
    "\n",
    "When you use model.predict(), Keras adds an extra dimension for the batch size. Even if you pass a single sequence, it treats it as a batch of size 1.\n",
    "\n",
    "This results in a 3D array of shape (1, 8, 10):\n",
    "\n",
    "1: Batch size (1 sequence).\n",
    "\n",
    "8: Sequence length (8 words).\n",
    "\n",
    "10: Embedding dimension (10 features per word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? ? the glass of milk\n"
     ]
    }
   ],
   "source": [
    "decoded_review = ' '.join([reverse_word_index.get(i, '?') for i in embedded_docs[0]])\n",
    "print(decoded_review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
